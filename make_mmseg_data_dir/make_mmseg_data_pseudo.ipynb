{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26b44d40-e411-4313-bc3e-282cf0fd997a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pycocotools.coco import COCO\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ad4e74-4d54-4a64-bf85-25ea8c848f6c",
   "metadata": {},
   "source": [
    "## Argument 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb872f67-09a0-4bc7-9863-3aacf7c14f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_data_dir  = '/opt/ml/segmentation/input/data'\n",
    "\n",
    "mode = 'train'\n",
    "# src_data_json_path = src_data_dir + '/train.json'\n",
    "src_data_json_path = src_data_dir + '/train_all.json'\n",
    "dst_data_dir = '/opt/ml/segmentation/input/mmseg_pseudo/'\n",
    "pseudo_num_duplicates = 1  # 2이면 train set이\n",
    "                           # train_all 데이터(3272개) + pseudo 데이터(819개) 2번 으로\n",
    "                           # 총 4910개로 구성된다.\n",
    "                           # 1이면 총 4091개가 된다.\n",
    "pseudo_ann_csv_path = './pan_se_resnext101_32x4d_train_all_20e_512.csv'\n",
    "                           # pseudo_num_duplicates이 0인 경우 쓰이지 않음\n",
    "\n",
    "# mode = 'val'\n",
    "# src_data_json_path = src_data_dir + '/val.json'\n",
    "# dst_data_dir = '/opt/ml/segmentation/input/mmseg_pseudo/'\n",
    "\n",
    "# mode = 'test'\n",
    "# src_data_json_path = src_data_dir + '/test.json'\n",
    "# dst_data_dir = '/opt/ml/segmentation/input/mmseg_pseudo/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84428a40-9621-498d-a236-c3403170cd85",
   "metadata": {},
   "source": [
    "## Dataset 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "546f9df0-7241-4717-9fe1-d8c8b4b9e472",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T06:16:06.631207Z",
     "start_time": "2021-10-04T06:16:06.620206Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "category_names = ['Backgroud', 'General trash', 'Paper', 'Paper pack', 'Metal', 'Glass', 'Plastic', 'Styrofoam', 'Plastic bag', 'Battery', 'Clothing']\n",
    "\n",
    "\n",
    "def get_classname(classID, cats):\n",
    "    for i in range(len(cats)):\n",
    "        if cats[i]['id']==classID:\n",
    "            return cats[i]['name']\n",
    "    return \"None\"\n",
    "\n",
    "\n",
    "class CustomDataLoader(Dataset):\n",
    "    \"\"\"COCO format\"\"\"\n",
    "    def __init__(self, data_dir, data_json_path, mode = 'train', transform = None):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "        \n",
    "        self.coco = COCO(data_json_path)\n",
    "        \n",
    "    def __getitem__(self, index: int):\n",
    "        # dataset이 index되어 list처럼 동작\n",
    "        image_id = self.coco.getImgIds(imgIds=index)\n",
    "        image_infos = self.coco.loadImgs(image_id)[0]\n",
    "        \n",
    "        # cv2 를 활용하여 image 불러오기\n",
    "        images = cv2.imread(os.path.join(self.data_dir, image_infos['file_name']))\n",
    "        # images = cv2.cvtColor(images, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        images = images.astype(np.float32)\n",
    "        # images /= 255.0\n",
    "        \n",
    "        if (self.mode in ('train', 'val')):\n",
    "            ann_ids = self.coco.getAnnIds(imgIds=image_infos['id'])\n",
    "            anns = self.coco.loadAnns(ann_ids)\n",
    "\n",
    "            # Load the categories in a variable\n",
    "            cat_ids = self.coco.getCatIds()\n",
    "            cats = self.coco.loadCats(cat_ids)\n",
    "\n",
    "            # masks : size가 (height x width)인 2D\n",
    "            # 각각의 pixel 값에는 \"category id\" 할당\n",
    "            # Background = 0\n",
    "            masks = np.zeros((image_infos[\"height\"], image_infos[\"width\"]))\n",
    "            # General trash = 1, ... , Cigarette = 10\n",
    "            anns = sorted(anns, key=lambda idx : idx['area'], reverse=True)\n",
    "            for i in range(len(anns)):\n",
    "                className = get_classname(anns[i]['category_id'], cats)\n",
    "                pixel_value = category_names.index(className)\n",
    "                masks[self.coco.annToMask(anns[i]) == 1] = pixel_value\n",
    "            masks = masks.astype(np.int8)\n",
    "                        \n",
    "            # transform -> albumentations 라이브러리 활용\n",
    "            if self.transform is not None:\n",
    "                transformed = self.transform(image=images, mask=masks)\n",
    "                images = transformed[\"image\"]\n",
    "                masks = transformed[\"mask\"]\n",
    "            return images, masks, image_infos\n",
    "        \n",
    "        if self.mode == 'test':\n",
    "            # transform -> albumentations 라이브러리 활용\n",
    "            if self.transform is not None:\n",
    "                transformed = self.transform(image=images)\n",
    "                images = transformed[\"image\"]\n",
    "            return images, image_infos\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        # 전체 dataset의 size를 return\n",
    "        return len(self.coco.getImgIds())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f86be72-b7d8-47be-9ac1-886e9abab367",
   "metadata": {},
   "source": [
    "### Pseudo 라벨 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a00ca65-a9a0-46ce-9819-c04fad6d5b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PseudoTrainDataset(Dataset):\n",
    "    def __init__(self, data_dir, ann_csv_path, transform = None):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.masks, self.image_infos = self.__load_annotations(ann_csv_path)\n",
    "\n",
    "    @staticmethod\n",
    "    def __load_annotations(ann_csv_path):\n",
    "        ann_df = pd.read_csv(ann_csv_path)\n",
    "        \n",
    "        masks = []\n",
    "        image_infos = []\n",
    "        for idx, (input_image_file_name, pred_str) in enumerate(zip(ann_df['image_id'], ann_df['PredictionString'])):\n",
    "            flatten_pred_ints = [int(pred) for pred in pred_str.split(' ')]\n",
    "            try:\n",
    "                mask = np.asarray(flatten_pred_ints, dtype=np.uint8).reshape(512, 512)\n",
    "            except ValueError as e:\n",
    "                print(idx)\n",
    "                raise e\n",
    "                \n",
    "            masks.append(mask)\n",
    "            \n",
    "            image_infos.append(\n",
    "                {\n",
    "                    'file_name': input_image_file_name,\n",
    "                    'id': idx\n",
    "                }\n",
    "            )\n",
    "        \n",
    "        return masks, image_infos\n",
    "        \n",
    "    def __getitem__(self, idx: int):\n",
    "        # cv2 를 활용하여 image 불러오기\n",
    "        image = cv2.imread(os.path.join(self.data_dir, self.image_infos[idx]['file_name']))\n",
    "        # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        image = image.astype(np.float32)\n",
    "        # image /= 255.0\n",
    "        \n",
    "        mask = self.masks[idx]\n",
    "        image_info = self.image_infos[idx]\n",
    "        \n",
    "        # transform -> albumentations 라이브러리 활용\n",
    "        if self.transform is not None:\n",
    "            transformed = self.transform(image=image, mask=mask)\n",
    "            image = transformed[\"image\"]\n",
    "            mask = transformed[\"mask\"]\n",
    "        \n",
    "        return image, mask, image_info\n",
    "        \n",
    "    def __len__(self) -> int:\n",
    "        # 전체 dataset의 size를 return\n",
    "        return len(self.masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f12c4d6-99c6-47a2-9869-9f483564c9ee",
   "metadata": {},
   "source": [
    "### Concat Two Datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee5f6990-42ab-470a-8284-dff23cd4eec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConcatTwoDataset(Dataset):  # only train mode\n",
    "    def __init__(self, dataset_1, dataset_2):\n",
    "        super().__init__()\n",
    "        self.dataset_1 = dataset_1\n",
    "        self.dataset_2 = dataset_2\n",
    "        \n",
    "        self.len_1 = len(dataset_1)\n",
    "        self.len_2 = len(dataset_2)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        if idx < self.len_1:\n",
    "            return self.dataset_1[idx]\n",
    "        else:\n",
    "            return self.dataset_2[idx-self.len_1]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.len_1 + self.len_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0579c86c-aa44-4dd6-91be-e783adead20d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dataset 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fef7f7b-6427-468f-b86a-8def5c2622b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T06:16:11.389706Z",
     "start_time": "2021-10-04T06:16:07.146708Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=4.80s)\n",
      "creating index...\n",
      "index created!\n",
      "length of dataset: 4091\n",
      "(array([[[158., 189., 212.],\n",
      "        [163., 194., 217.],\n",
      "        [160., 189., 216.],\n",
      "        ...,\n",
      "        [108., 132., 160.],\n",
      "        [108., 132., 160.],\n",
      "        [107., 131., 159.]],\n",
      "\n",
      "       [[168., 198., 223.],\n",
      "        [158., 188., 213.],\n",
      "        [155., 184., 211.],\n",
      "        ...,\n",
      "        [107., 131., 159.],\n",
      "        [107., 131., 159.],\n",
      "        [107., 131., 159.]],\n",
      "\n",
      "       [[161., 190., 217.],\n",
      "        [165., 194., 221.],\n",
      "        [162., 191., 218.],\n",
      "        ...,\n",
      "        [106., 131., 157.],\n",
      "        [106., 130., 158.],\n",
      "        [105., 129., 157.]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[228., 222., 227.],\n",
      "        [226., 222., 227.],\n",
      "        [228., 222., 227.],\n",
      "        ...,\n",
      "        [127., 117., 130.],\n",
      "        [130., 117., 131.],\n",
      "        [129., 116., 130.]],\n",
      "\n",
      "       [[213., 209., 215.],\n",
      "        [212., 210., 216.],\n",
      "        [214., 210., 216.],\n",
      "        ...,\n",
      "        [131., 118., 132.],\n",
      "        [130., 117., 131.],\n",
      "        [129., 116., 130.]],\n",
      "\n",
      "       [[187., 184., 193.],\n",
      "        [188., 185., 194.],\n",
      "        [189., 187., 193.],\n",
      "        ...,\n",
      "        [134., 121., 135.],\n",
      "        [132., 119., 133.],\n",
      "        [133., 120., 134.]]], dtype=float32), array([[0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), {'license': 0, 'url': None, 'file_name': 'batch_01_vt/0002.jpg', 'height': 512, 'width': 512, 'date_captured': None, 'id': 0})\n",
      "(array([[[ 66.,  62.,  67.],\n",
      "        [156., 152., 157.],\n",
      "        [205., 201., 206.],\n",
      "        ...,\n",
      "        [ 60.,  57.,  66.],\n",
      "        [ 60.,  56.,  67.],\n",
      "        [ 58.,  54.,  65.]],\n",
      "\n",
      "       [[ 96.,  92.,  97.],\n",
      "        [202., 198., 203.],\n",
      "        [206., 202., 207.],\n",
      "        ...,\n",
      "        [ 58.,  55.,  64.],\n",
      "        [ 58.,  54.,  65.],\n",
      "        [ 56.,  52.,  63.]],\n",
      "\n",
      "       [[156., 152., 157.],\n",
      "        [219., 215., 220.],\n",
      "        [207., 203., 208.],\n",
      "        ...,\n",
      "        [ 57.,  54.,  63.],\n",
      "        [ 56.,  53.,  62.],\n",
      "        [ 54.,  51.,  60.]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 94.,  88.,  93.],\n",
      "        [101.,  95., 100.],\n",
      "        [103.,  97., 102.],\n",
      "        ...,\n",
      "        [126., 113., 115.],\n",
      "        [129., 116., 118.],\n",
      "        [133., 120., 122.]],\n",
      "\n",
      "       [[ 96.,  89.,  94.],\n",
      "        [101.,  94.,  99.],\n",
      "        [100.,  93.,  98.],\n",
      "        ...,\n",
      "        [126., 112., 116.],\n",
      "        [128., 114., 118.],\n",
      "        [128., 114., 118.]],\n",
      "\n",
      "       [[ 75.,  68.,  73.],\n",
      "        [ 77.,  70.,  75.],\n",
      "        [ 75.,  68.,  73.],\n",
      "        ...,\n",
      "        [125., 111., 115.],\n",
      "        [126., 112., 116.],\n",
      "        [122., 108., 112.]]], dtype=float32), array([[0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8), {'file_name': 'batch_03/0998.jpg', 'id': 818})\n"
     ]
    }
   ],
   "source": [
    "common_transform = A.Compose([ToTensorV2()])\n",
    "\n",
    "dataset = CustomDataLoader(data_dir=src_data_dir, data_json_path=src_data_json_path, mode=mode, transform=None)\n",
    "\n",
    "if mode == 'train' and pseudo_num_duplicates > 0:\n",
    "    pseudo_dataset = PseudoTrainDataset(src_data_dir, pseudo_ann_csv_path, transform=None)\n",
    "    for _ in range(pseudo_num_duplicates):\n",
    "        dataset = ConcatTwoDataset(dataset, pseudo_dataset)\n",
    "\n",
    "print(f\"length of dataset: {len(dataset)}\")\n",
    "print(dataset[0])\n",
    "if pseudo_num_duplicates > 0:\n",
    "    print(dataset[4090])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f0623c-b13a-4850-a02b-4d60b6edbc80",
   "metadata": {},
   "source": [
    "## image 및 annotation 저장"
   ]
  },
  {
   "cell_type": "raw",
   "id": "42d45741-0fdc-4f81-b4a2-4af0f209601e",
   "metadata": {},
   "source": [
    "├── input\n",
    "│   ├── mmseg\n",
    "│   │   ├── image\n",
    "│   │   │   ├── training\n",
    "│   │   │   │   ├── xxx{img_suffix}\n",
    "│   │   │   │   ├── yyy{img_suffix}\n",
    "│   │   │   │   ├── zzz{img_suffix}\n",
    "│   │   │   ├── validation\n",
    "│   │   ├── annotation\n",
    "│   │   │   ├── training\n",
    "│   │   │   │   ├── xxx{seg_map_suffix}\n",
    "│   │   │   │   ├── yyy{seg_map_suffix}\n",
    "│   │   │   │   ├── zzz{seg_map_suffix}\n",
    "│   │   │   └── validation\n",
    "│   │   └── test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ed80de1-03c1-4dd1-a3e1-dfac7fc33a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/4091 [00:00<01:12, 56.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A directory - /opt/ml/segmentation/input/mmseg_pseudo/images/training is created.\n",
      "A directory - /opt/ml/segmentation/input/mmseg_pseudo/annotations/training is created.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4091/4091 [01:13<00:00, 55.49it/s]\n"
     ]
    }
   ],
   "source": [
    "if mode == 'train':\n",
    "    images_save_dir = os.path.join(dst_data_dir, 'images/training')\n",
    "    annotations_save_dir = os.path.join(dst_data_dir, 'annotations/training')\n",
    "elif mode == 'val':\n",
    "    images_save_dir = os.path.join(dst_data_dir, 'images/validation')\n",
    "    annotations_save_dir = os.path.join(dst_data_dir, 'annotations/validation')\n",
    "else:  # mode == 'test'\n",
    "    images_save_dir = os.path.join(dst_data_dir, 'test')\n",
    "    annotations_save_dir = None\n",
    "    \n",
    "if not os.path.exists(images_save_dir):\n",
    "    os.makedirs(images_save_dir)\n",
    "    print('A directory - ' + images_save_dir + ' is created.')\n",
    "          \n",
    "if annotations_save_dir and not os.path.exists(annotations_save_dir):\n",
    "    os.makedirs(annotations_save_dir)\n",
    "    print('A directory - ' + annotations_save_dir + ' is created.')\n",
    "    \n",
    "\n",
    "if mode in ('train', 'val'):\n",
    "    for idx in tqdm(range(len(dataset))):\n",
    "        img, mask, image_infos = dataset[idx]\n",
    "        image_save_path = os.path.join(images_save_dir, f'{idx:04}.jpg')  \n",
    "        # image_infos[\"id\"]로 할 경우, train data의 id와 pseudo data(test data)의 id가 겹치게 된다.\n",
    "        annotation_save_path = os.path.join(annotations_save_dir, f'{idx:04}.png')\n",
    "        \n",
    "        cv2.imwrite(image_save_path, img)\n",
    "        cv2.imwrite(annotation_save_path, mask)\n",
    "\n",
    "elif mode == 'test':\n",
    "    for idx in tqdm(range(len(dataset))):\n",
    "        img, image_infos = dataset[idx]\n",
    "        image_save_path = os.path.join(images_save_dir, f'{image_infos[\"id\"]:04}.jpg')\n",
    "        \n",
    "        cv2.imwrite(image_save_path, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf57c13-c4f8-4a06-9754-b8ff286a1463",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "segmentation",
   "language": "python",
   "name": "segmentation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
