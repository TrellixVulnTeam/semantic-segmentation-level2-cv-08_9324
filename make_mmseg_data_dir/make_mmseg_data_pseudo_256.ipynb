{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26b44d40-e411-4313-bc3e-282cf0fd997a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pycocotools.coco import COCO\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ad4e74-4d54-4a64-bf85-25ea8c848f6c",
   "metadata": {},
   "source": [
    "## Argument 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb872f67-09a0-4bc7-9863-3aacf7c14f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_data_dir  = '/opt/ml/segmentation/input/data'\n",
    "\n",
    "mode = 'train'\n",
    "# src_data_json_path = src_data_dir + '/train.json'\n",
    "src_data_json_path = src_data_dir + '/train_all.json'\n",
    "dst_data_dir = '/opt/ml/segmentation/input/mmseg_pseudo/'\n",
    "pseudo_num_duplicates = 2  # 2이면 train set이\n",
    "                           # train_all 데이터(3272개) + pseudo 데이터(819개) 2번 으로\n",
    "                           # 총 4910개로 구성된다.\n",
    "                           # 1이면 총 4091개가 된다.\n",
    "pseudo_ann_csv_path = './hard_voting_ensemble_jhSwin_0.767_ws_Swin_0.747_bs_deeplabv3_0.700.csv'\n",
    "                           # 이 노트북은 256 x 256 으로 저장된 csv를 사용\n",
    "                           # pseudo_num_duplicates이 0인 경우 쓰이지 않음\n",
    "\n",
    "# mode = 'val'\n",
    "# src_data_json_path = src_data_dir + '/val.json'\n",
    "# dst_data_dir = '/opt/ml/segmentation/input/mmseg_pseudo/'\n",
    "\n",
    "# mode = 'test'\n",
    "# src_data_json_path = src_data_dir + '/test.json'\n",
    "# dst_data_dir = '/opt/ml/segmentation/input/mmseg_pseudo/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84428a40-9621-498d-a236-c3403170cd85",
   "metadata": {},
   "source": [
    "## Dataset 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "546f9df0-7241-4717-9fe1-d8c8b4b9e472",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T06:16:06.631207Z",
     "start_time": "2021-10-04T06:16:06.620206Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "category_names = ['Backgroud', 'General trash', 'Paper', 'Paper pack', 'Metal', 'Glass', 'Plastic', 'Styrofoam', 'Plastic bag', 'Battery', 'Clothing']\n",
    "\n",
    "\n",
    "def get_classname(classID, cats):\n",
    "    for i in range(len(cats)):\n",
    "        if cats[i]['id']==classID:\n",
    "            return cats[i]['name']\n",
    "    return \"None\"\n",
    "\n",
    "\n",
    "class CustomDataLoader(Dataset):\n",
    "    \"\"\"COCO format\"\"\"\n",
    "    def __init__(self, data_dir, data_json_path, mode = 'train', transform = None):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "        \n",
    "        self.coco = COCO(data_json_path)\n",
    "        \n",
    "    def __getitem__(self, index: int):\n",
    "        # dataset이 index되어 list처럼 동작\n",
    "        image_id = self.coco.getImgIds(imgIds=index)\n",
    "        image_infos = self.coco.loadImgs(image_id)[0]\n",
    "        \n",
    "        # cv2 를 활용하여 image 불러오기\n",
    "        images = cv2.imread(os.path.join(self.data_dir, image_infos['file_name']))\n",
    "        # images = cv2.cvtColor(images, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        images = images.astype(np.float32)\n",
    "        # images /= 255.0\n",
    "        \n",
    "        if (self.mode in ('train', 'val')):\n",
    "            ann_ids = self.coco.getAnnIds(imgIds=image_infos['id'])\n",
    "            anns = self.coco.loadAnns(ann_ids)\n",
    "\n",
    "            # Load the categories in a variable\n",
    "            cat_ids = self.coco.getCatIds()\n",
    "            cats = self.coco.loadCats(cat_ids)\n",
    "\n",
    "            # masks : size가 (height x width)인 2D\n",
    "            # 각각의 pixel 값에는 \"category id\" 할당\n",
    "            # Background = 0\n",
    "            masks = np.zeros((image_infos[\"height\"], image_infos[\"width\"]))\n",
    "            # General trash = 1, ... , Cigarette = 10\n",
    "            anns = sorted(anns, key=lambda idx : idx['area'], reverse=True)\n",
    "            for i in range(len(anns)):\n",
    "                className = get_classname(anns[i]['category_id'], cats)\n",
    "                pixel_value = category_names.index(className)\n",
    "                masks[self.coco.annToMask(anns[i]) == 1] = pixel_value\n",
    "            masks = masks.astype(np.int8)\n",
    "                        \n",
    "            # transform -> albumentations 라이브러리 활용\n",
    "            if self.transform is not None:\n",
    "                transformed = self.transform(image=images, mask=masks)\n",
    "                images = transformed[\"image\"]\n",
    "                masks = transformed[\"mask\"]\n",
    "            return images, masks, image_infos\n",
    "        \n",
    "        if self.mode == 'test':\n",
    "            # transform -> albumentations 라이브러리 활용\n",
    "            if self.transform is not None:\n",
    "                transformed = self.transform(image=images)\n",
    "                images = transformed[\"image\"]\n",
    "            return images, image_infos\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        # 전체 dataset의 size를 return\n",
    "        return len(self.coco.getImgIds())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f86be72-b7d8-47be-9ac1-886e9abab367",
   "metadata": {},
   "source": [
    "### Pseudo 라벨 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a00ca65-a9a0-46ce-9819-c04fad6d5b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_transform = A.Compose([A.Resize(512, 512, 0)])  # cv2.INTER_NEAREST\n",
    "\n",
    "class PseudoTrainDataset(Dataset):\n",
    "    def __init__(self, data_dir, ann_csv_path, transform = None):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.masks, self.image_infos = self.__load_annotations(ann_csv_path)\n",
    "\n",
    "    @staticmethod\n",
    "    def __load_annotations(ann_csv_path):\n",
    "        ann_df = pd.read_csv(ann_csv_path)\n",
    "        \n",
    "        masks = []\n",
    "        image_infos = []\n",
    "        for idx, (input_image_file_name, pred_str) in enumerate(zip(ann_df['image_id'], ann_df['PredictionString'])):\n",
    "            flatten_pred_ints = [int(pred) for pred in pred_str.split(' ')]\n",
    "            try:\n",
    "                mask = np.asarray(flatten_pred_ints, dtype=np.uint8).reshape(256, 256)\n",
    "            except ValueError as e:\n",
    "                print(idx)\n",
    "                raise e\n",
    "                \n",
    "            masks.append(mask)\n",
    "            \n",
    "            image_infos.append(\n",
    "                {\n",
    "                    'file_name': input_image_file_name,\n",
    "                    'id': idx\n",
    "                }\n",
    "            )\n",
    "        \n",
    "        return masks, image_infos\n",
    "        \n",
    "    def __getitem__(self, idx: int):\n",
    "        # cv2 를 활용하여 image 불러오기\n",
    "        image = cv2.imread(os.path.join(self.data_dir, self.image_infos[idx]['file_name']))\n",
    "        # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        image = image.astype(np.float32)\n",
    "        # image /= 255.0\n",
    "        \n",
    "        mask = self.masks[idx]\n",
    "        image_info = self.image_infos[idx]\n",
    "        \n",
    "        mask = resize_transform(image=image, mask=mask)[\"mask\"]  # image 입력을 안하면 error 발생하여, 필요없이 넣는다.\n",
    "        \n",
    "        # transform -> albumentations 라이브러리 활용\n",
    "        if self.transform is not None:\n",
    "            transformed = self.transform(image=image, mask=mask)\n",
    "            image = transformed[\"image\"]\n",
    "            mask = transformed[\"mask\"]\n",
    "        \n",
    "        return image, mask, image_info\n",
    "        \n",
    "    def __len__(self) -> int:\n",
    "        # 전체 dataset의 size를 return\n",
    "        return len(self.masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f12c4d6-99c6-47a2-9869-9f483564c9ee",
   "metadata": {},
   "source": [
    "### Concat Two Datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee5f6990-42ab-470a-8284-dff23cd4eec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConcatTwoDataset(Dataset):  # only train mode\n",
    "    def __init__(self, dataset_1, dataset_2):\n",
    "        super().__init__()\n",
    "        self.dataset_1 = dataset_1\n",
    "        self.dataset_2 = dataset_2\n",
    "        \n",
    "        self.len_1 = len(dataset_1)\n",
    "        self.len_2 = len(dataset_2)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        if idx < self.len_1:\n",
    "            return self.dataset_1[idx]\n",
    "        else:\n",
    "            return self.dataset_2[idx-self.len_1]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.len_1 + self.len_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0579c86c-aa44-4dd6-91be-e783adead20d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dataset 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fef7f7b-6427-468f-b86a-8def5c2622b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T06:16:11.389706Z",
     "start_time": "2021-10-04T06:16:07.146708Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=4.95s)\n",
      "creating index...\n",
      "index created!\n",
      "length of dataset: 4910\n",
      "(512, 512)\n",
      "(512, 512)\n"
     ]
    }
   ],
   "source": [
    "common_transform = A.Compose([ToTensorV2()])\n",
    "\n",
    "dataset = CustomDataLoader(data_dir=src_data_dir, data_json_path=src_data_json_path, mode=mode, transform=None)\n",
    "\n",
    "if mode == 'train' and pseudo_num_duplicates > 0:\n",
    "    pseudo_dataset = PseudoTrainDataset(src_data_dir, pseudo_ann_csv_path, transform=None)\n",
    "    for _ in range(pseudo_num_duplicates):\n",
    "        dataset = ConcatTwoDataset(dataset, pseudo_dataset)\n",
    "\n",
    "print(f\"length of dataset: {len(dataset)}\")\n",
    "if mode == 'train' and pseudo_num_duplicates > 0:\n",
    "    print(dataset[0][1].shape)\n",
    "    print(dataset[4090][1].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f0623c-b13a-4850-a02b-4d60b6edbc80",
   "metadata": {},
   "source": [
    "## image 및 annotation 저장"
   ]
  },
  {
   "cell_type": "raw",
   "id": "42d45741-0fdc-4f81-b4a2-4af0f209601e",
   "metadata": {},
   "source": [
    "├── input\n",
    "│   ├── mmseg\n",
    "│   │   ├── image\n",
    "│   │   │   ├── training\n",
    "│   │   │   │   ├── xxx{img_suffix}\n",
    "│   │   │   │   ├── yyy{img_suffix}\n",
    "│   │   │   │   ├── zzz{img_suffix}\n",
    "│   │   │   ├── validation\n",
    "│   │   ├── annotation\n",
    "│   │   │   ├── training\n",
    "│   │   │   │   ├── xxx{seg_map_suffix}\n",
    "│   │   │   │   ├── yyy{seg_map_suffix}\n",
    "│   │   │   │   ├── zzz{seg_map_suffix}\n",
    "│   │   │   └── validation\n",
    "│   │   └── test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ed80de1-03c1-4dd1-a3e1-dfac7fc33a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/4910 [00:00<01:23, 58.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A directory - /opt/ml/segmentation/input/mmseg_pseudo/images/training is created.\n",
      "A directory - /opt/ml/segmentation/input/mmseg_pseudo/annotations/training is created.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4910/4910 [01:23<00:00, 58.98it/s]\n"
     ]
    }
   ],
   "source": [
    "if mode == 'train':\n",
    "    images_save_dir = os.path.join(dst_data_dir, 'images/training')\n",
    "    annotations_save_dir = os.path.join(dst_data_dir, 'annotations/training')\n",
    "elif mode == 'val':\n",
    "    images_save_dir = os.path.join(dst_data_dir, 'images/validation')\n",
    "    annotations_save_dir = os.path.join(dst_data_dir, 'annotations/validation')\n",
    "else:  # mode == 'test'\n",
    "    images_save_dir = os.path.join(dst_data_dir, 'test')\n",
    "    annotations_save_dir = None\n",
    "    \n",
    "if not os.path.exists(images_save_dir):\n",
    "    os.makedirs(images_save_dir)\n",
    "    print('A directory - ' + images_save_dir + ' is created.')\n",
    "          \n",
    "if annotations_save_dir and not os.path.exists(annotations_save_dir):\n",
    "    os.makedirs(annotations_save_dir)\n",
    "    print('A directory - ' + annotations_save_dir + ' is created.')\n",
    "    \n",
    "\n",
    "if mode in ('train', 'val'):\n",
    "    for idx in tqdm(range(len(dataset))):\n",
    "        img, mask, image_infos = dataset[idx]\n",
    "        image_save_path = os.path.join(images_save_dir, f'{idx:04}.jpg')  \n",
    "        # image_infos[\"id\"]로 할 경우, train data의 id와 pseudo data(test data)의 id가 겹치게 된다.\n",
    "        annotation_save_path = os.path.join(annotations_save_dir, f'{idx:04}.png')\n",
    "        \n",
    "        cv2.imwrite(image_save_path, img)\n",
    "        cv2.imwrite(annotation_save_path, mask)\n",
    "\n",
    "elif mode == 'test':\n",
    "    for idx in tqdm(range(len(dataset))):\n",
    "        img, image_infos = dataset[idx]\n",
    "        image_save_path = os.path.join(images_save_dir, f'{image_infos[\"id\"]:04}.jpg')\n",
    "        \n",
    "        cv2.imwrite(image_save_path, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf57c13-c4f8-4a06-9754-b8ff286a1463",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "segmentation",
   "language": "python",
   "name": "segmentation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
