{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26b44d40-e411-4313-bc3e-282cf0fd997a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pycocotools.coco import COCO\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ad4e74-4d54-4a64-bf85-25ea8c848f6c",
   "metadata": {},
   "source": [
    "## Argument 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb872f67-09a0-4bc7-9863-3aacf7c14f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_data_dir  = '/opt/ml/segmentation/input/data'\n",
    "\n",
    "mode = 'train'\n",
    "src_data_json_path = src_data_dir + '/train.json'\n",
    "# src_data_json_path = src_data_dir + '/train_all.json'\n",
    "dst_data_dir = '/opt/ml/segmentation/input/mmseg/'\n",
    "\n",
    "# mode = 'val'\n",
    "# src_data_json_path = src_data_dir + '/val.json'\n",
    "# dst_data_dir = '/opt/ml/segmentation/input/mmseg/'\n",
    "\n",
    "# mode = 'test'\n",
    "# src_data_json_path = src_data_dir + '/test.json'\n",
    "# dst_data_dir = '/opt/ml/segmentation/input/mmseg/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84428a40-9621-498d-a236-c3403170cd85",
   "metadata": {},
   "source": [
    "## Dataset 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "546f9df0-7241-4717-9fe1-d8c8b4b9e472",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T06:16:06.631207Z",
     "start_time": "2021-10-04T06:16:06.620206Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "category_names = ['Backgroud', 'General trash', 'Paper', 'Paper pack', 'Metal', 'Glass', 'Plastic', 'Styrofoam', 'Plastic bag', 'Battery', 'Clothing']\n",
    "\n",
    "\n",
    "def get_classname(classID, cats):\n",
    "    for i in range(len(cats)):\n",
    "        if cats[i]['id']==classID:\n",
    "            return cats[i]['name']\n",
    "    return \"None\"\n",
    "\n",
    "\n",
    "class CustomDataLoader(Dataset):\n",
    "    \"\"\"COCO format\"\"\"\n",
    "    def __init__(self, data_dir, data_json_path, mode = 'train', transform = None):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "        \n",
    "        self.coco = COCO(data_json_path)\n",
    "        \n",
    "    def __getitem__(self, index: int):\n",
    "        # dataset이 index되어 list처럼 동작\n",
    "        image_id = self.coco.getImgIds(imgIds=index)\n",
    "        image_infos = self.coco.loadImgs(image_id)[0]\n",
    "        \n",
    "        # cv2 를 활용하여 image 불러오기\n",
    "        images = cv2.imread(os.path.join(self.data_dir, image_infos['file_name']))\n",
    "        # images = cv2.cvtColor(images, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        images = images.astype(np.float32)\n",
    "        # images /= 255.0\n",
    "        \n",
    "        if (self.mode in ('train', 'val')):\n",
    "            ann_ids = self.coco.getAnnIds(imgIds=image_infos['id'])\n",
    "            anns = self.coco.loadAnns(ann_ids)\n",
    "\n",
    "            # Load the categories in a variable\n",
    "            cat_ids = self.coco.getCatIds()\n",
    "            cats = self.coco.loadCats(cat_ids)\n",
    "\n",
    "            # masks : size가 (height x width)인 2D\n",
    "            # 각각의 pixel 값에는 \"category id\" 할당\n",
    "            # Background = 0\n",
    "            masks = np.zeros((image_infos[\"height\"], image_infos[\"width\"]))\n",
    "            # General trash = 1, ... , Cigarette = 10\n",
    "            anns = sorted(anns, key=lambda idx : len(idx['segmentation'][0]), reverse=False)\n",
    "            for i in range(len(anns)):\n",
    "                className = get_classname(anns[i]['category_id'], cats)\n",
    "                pixel_value = category_names.index(className)\n",
    "                masks[self.coco.annToMask(anns[i]) == 1] = pixel_value\n",
    "            masks = masks.astype(np.int8)\n",
    "                        \n",
    "            # transform -> albumentations 라이브러리 활용\n",
    "            if self.transform is not None:\n",
    "                transformed = self.transform(image=images, mask=masks)\n",
    "                images = transformed[\"image\"]\n",
    "                masks = transformed[\"mask\"]\n",
    "            return images, masks, image_infos\n",
    "        \n",
    "        if self.mode == 'test':\n",
    "            # transform -> albumentations 라이브러리 활용\n",
    "            if self.transform is not None:\n",
    "                transformed = self.transform(image=images)\n",
    "                images = transformed[\"image\"]\n",
    "            return images, image_infos\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        # 전체 dataset의 size를 return\n",
    "        return len(self.coco.getImgIds())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0579c86c-aa44-4dd6-91be-e783adead20d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dataset 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fef7f7b-6427-468f-b86a-8def5c2622b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T06:16:11.389706Z",
     "start_time": "2021-10-04T06:16:07.146708Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[[ 77.,  86.,  89.],\n",
       "         [ 70.,  79.,  82.],\n",
       "         [ 63.,  72.,  75.],\n",
       "         ...,\n",
       "         [ 18.,  20.,  28.],\n",
       "         [ 18.,  20.,  28.],\n",
       "         [ 18.,  20.,  28.]],\n",
       " \n",
       "        [[ 68.,  77.,  80.],\n",
       "         [ 66.,  75.,  78.],\n",
       "         [ 61.,  70.,  73.],\n",
       "         ...,\n",
       "         [ 18.,  20.,  28.],\n",
       "         [ 17.,  19.,  27.],\n",
       "         [ 17.,  19.,  27.]],\n",
       " \n",
       "        [[ 46.,  55.,  58.],\n",
       "         [ 47.,  56.,  59.],\n",
       "         [ 45.,  54.,  57.],\n",
       "         ...,\n",
       "         [ 17.,  19.,  27.],\n",
       "         [ 17.,  19.,  27.],\n",
       "         [ 16.,  18.,  26.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 46.,  58.,  76.],\n",
       "         [ 33.,  45.,  63.],\n",
       "         [ 31.,  43.,  61.],\n",
       "         ...,\n",
       "         [ 82., 100., 111.],\n",
       "         [ 43.,  55.,  67.],\n",
       "         [ 44.,  54.,  64.]],\n",
       " \n",
       "        [[ 31.,  45.,  63.],\n",
       "         [ 23.,  37.,  55.],\n",
       "         [ 25.,  39.,  57.],\n",
       "         ...,\n",
       "         [ 72.,  94., 105.],\n",
       "         [ 38.,  54.,  66.],\n",
       "         [ 44.,  56.,  68.]],\n",
       " \n",
       "        [[ 31.,  45.,  63.],\n",
       "         [ 23.,  37.,  55.],\n",
       "         [ 27.,  41.,  59.],\n",
       "         ...,\n",
       "         [ 78., 102., 114.],\n",
       "         [ 47.,  63.,  75.],\n",
       "         [ 42.,  56.,  68.]]], dtype=float32),\n",
       " {'license': 0,\n",
       "  'url': None,\n",
       "  'file_name': 'batch_01_vt/0021.jpg',\n",
       "  'height': 512,\n",
       "  'width': 512,\n",
       "  'date_captured': None,\n",
       "  'id': 0})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_transform = A.Compose([ToTensorV2()])\n",
    "\n",
    "\n",
    "dataset = CustomDataLoader(data_dir=src_data_dir, data_json_path=src_data_json_path, mode=mode, transform=None)\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f0623c-b13a-4850-a02b-4d60b6edbc80",
   "metadata": {},
   "source": [
    "## image 및 annotation 저장"
   ]
  },
  {
   "cell_type": "raw",
   "id": "42d45741-0fdc-4f81-b4a2-4af0f209601e",
   "metadata": {},
   "source": [
    "├── input\n",
    "│   ├── mmseg\n",
    "│   │   ├── image\n",
    "│   │   │   ├── training\n",
    "│   │   │   │   ├── xxx{img_suffix}\n",
    "│   │   │   │   ├── yyy{img_suffix}\n",
    "│   │   │   │   ├── zzz{img_suffix}\n",
    "│   │   │   ├── validation\n",
    "│   │   ├── annotation\n",
    "│   │   │   ├── training\n",
    "│   │   │   │   ├── xxx{seg_map_suffix}\n",
    "│   │   │   │   ├── yyy{seg_map_suffix}\n",
    "│   │   │   │   ├── zzz{seg_map_suffix}\n",
    "│   │   │   └── validation\n",
    "│   │   └── test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ed80de1-03c1-4dd1-a3e1-dfac7fc33a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 9/819 [00:00<00:09, 89.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A directory - /opt/ml/segmentation/input/mmseg/test is created.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 819/819 [00:09<00:00, 89.66it/s]\n"
     ]
    }
   ],
   "source": [
    "if mode == 'train':\n",
    "    images_save_dir = os.path.join(dst_data_dir, 'images/training')\n",
    "    annotations_save_dir = os.path.join(dst_data_dir, 'annotations/training')\n",
    "elif mode == 'val':\n",
    "    images_save_dir = os.path.join(dst_data_dir, 'images/validation')\n",
    "    annotations_save_dir = os.path.join(dst_data_dir, 'annotations/validation')\n",
    "else:  # mode == 'test'\n",
    "    images_save_dir = os.path.join(dst_data_dir, 'test')\n",
    "    annotations_save_dir = None\n",
    "    \n",
    "if not os.path.exists(images_save_dir):\n",
    "    os.makedirs(images_save_dir)\n",
    "    print('A directory - ' + images_save_dir + ' is created.')\n",
    "          \n",
    "if annotations_save_dir and not os.path.exists(annotations_save_dir):\n",
    "    os.makedirs(annotations_save_dir)\n",
    "    print('A directory - ' + annotations_save_dir + ' is created.')\n",
    "    \n",
    "\n",
    "if mode in ('train', 'val'):\n",
    "    for idx in tqdm(range(len(dataset))):\n",
    "        img, mask, image_infos = dataset[idx]\n",
    "        image_save_path = os.path.join(images_save_dir, f'{image_infos[\"id\"]:04}.jpg')\n",
    "        annotation_save_path = os.path.join(annotations_save_dir, f'{image_infos[\"id\"]:04}.png')\n",
    "        \n",
    "        cv2.imwrite(image_save_path, img)\n",
    "        cv2.imwrite(annotation_save_path, mask)\n",
    "\n",
    "elif mode == 'test':\n",
    "    for idx in tqdm(range(len(dataset))):\n",
    "        img, image_infos = dataset[idx]\n",
    "        image_save_path = os.path.join(images_save_dir, f'{image_infos[\"id\"]:04}.jpg')\n",
    "        \n",
    "        cv2.imwrite(image_save_path, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf57c13-c4f8-4a06-9754-b8ff286a1463",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "segmentation",
   "language": "python",
   "name": "segmentation"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
